{"timestamp":"2026-01-27T23:24:45.099823Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:24:47.143037Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:24:47.309062Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:24:47.311057Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:24:47.410835Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:24:47.416829Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:24:47.416885Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:24:47.416918Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:25:18.232218Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:25:18.904648Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:25:19.033573Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:25:19.033808Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:25:19.101345Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:25:19.102898Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:25:19.102940Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:25:19.102970Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:25:49.526591Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:25:50.184027Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:25:50.313495Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:25:50.315599Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:25:50.379794Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:25:50.381788Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:25:50.381834Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:25:50.381864Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:26:20.875713Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:26:21.545189Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:26:21.669936Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:26:21.670197Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:26:21.731167Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:26:21.733043Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:26:21.733095Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:26:21.733127Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:26:52.234578Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:26:53.025714Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:26:53.153986Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:26:53.154198Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:26:53.195029Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:26:53.197076Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:26:53.197127Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:26:53.197157Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:27:24.669588Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:27:26.106514Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:27:26.247846Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:27:26.248021Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:27:26.279799Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:27:26.281932Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:27:26.281991Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:27:26.282024Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:32:59.532440Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:33:00.230649Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:33:00.367591Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:33:00.367893Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:33:00.401506Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:33:00.403350Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:33:00.403401Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:33:00.403432Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:33:31.239600Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:33:31.842700Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:33:31.965413Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:33:31.965694Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:33:32.037853Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:33:32.039257Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:33:32.039301Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:33:32.039331Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:34:02.538159Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:34:03.139895Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:34:03.262912Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:34:03.263861Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:34:03.335115Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:34:03.336977Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:34:03.337024Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:34:03.337054Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:34:34.216183Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:34:34.829142Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:34:34.956255Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:34:34.956493Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:34:35.024740Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:34:35.026454Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:34:35.026503Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:34:35.026535Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:35:05.944277Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:35:06.579675Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:35:06.712690Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:35:06.713063Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:35:06.760888Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:35:06.762926Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:35:06.762980Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:35:06.763012Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:35:37.187876Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:35:37.805184Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:35:37.938219Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:35:37.938678Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:35:37.997094Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:35:37.998816Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:35:37.998861Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:35:37.998890Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:36:08.478109Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:36:09.174035Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:36:09.342534Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:36:09.345301Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:36:09.401970Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:36:09.403510Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:36:09.403561Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:36:09.403595Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:36:39.861266Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:36:40.516671Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:36:40.667272Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:36:40.667491Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:36:40.785793Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:36:40.787656Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:36:40.787811Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:36:40.787887Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:37:11.238628Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:37:11.918073Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:37:12.060634Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:37:12.060907Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:37:12.079780Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:37:12.081459Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:37:12.081505Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:37:12.081535Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:37:42.557827Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:37:43.180952Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:37:43.303806Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:37:43.304028Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:37:43.366553Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:37:43.367996Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:37:43.368041Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:37:43.368071Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:38:13.837471Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:38:14.453259Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:38:14.575394Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:38:14.575627Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:38:14.656383Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:38:14.657901Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:38:14.657946Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:38:14.657976Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:38:45.124339Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:38:45.724623Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:38:45.848752Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:38:45.848983Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:38:45.918194Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:38:45.919995Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:38:45.920039Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:38:45.920067Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:39:16.739734Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:39:17.410813Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:39:17.543555Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:39:17.543766Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:39:17.641712Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:39:17.643361Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:39:17.643409Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:39:17.643443Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:39:48.113782Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:39:48.771271Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:39:48.905161Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:39:48.905491Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:39:48.944946Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:39:48.946599Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:39:48.946645Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:39:48.946674Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:40:19.398196Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:40:19.992964Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:40:20.115410Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:40:20.115634Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:40:20.202318Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:40:20.204411Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:40:20.204460Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:40:20.204492Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:40:50.654328Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:40:51.276952Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:40:51.409982Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:40:51.410202Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:40:51.483654Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:40:51.485230Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:40:51.485274Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:40:51.485305Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:41:22.295930Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:41:22.969922Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:41:23.096084Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:41:23.096458Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:41:23.145519Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:41:23.147152Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:41:23.147197Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:41:23.147226Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:43:28.514726Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:43:30.009143Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:43:30.149342Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:43:30.159559Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:43:30.230167Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:43:30.233489Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:43:30.233546Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:43:30.233581Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:44:00.994240Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:44:01.782492Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:44:01.904010Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:44:01.906124Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:44:01.969880Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:44:01.971784Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:44:01.971830Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:44:01.971860Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:44:32.830390Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:44:33.519944Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:44:33.642767Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:44:33.643306Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:44:33.701784Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:44:33.703663Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:44:33.703710Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:44:33.703742Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:45:04.564584Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:45:05.236000Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:45:05.360142Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:45:05.360985Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:45:05.414858Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:45:05.416771Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:45:05.416818Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:45:05.416848Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:45:36.270435Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:45:36.912219Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:45:37.032895Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:45:37.033169Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:45:37.123846Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:45:37.125826Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:45:37.125876Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:45:37.125907Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:46:07.966365Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:46:08.613452Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:46:08.743800Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:46:08.747048Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:46:08.822439Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:46:08.823894Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:46:08.823940Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:46:08.823971Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:46:39.340886Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:46:39.928027Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:46:40.050756Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:46:40.051061Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:46:40.133458Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:46:40.135048Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:46:40.135094Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:46:40.135126Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:47:10.594730Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:47:11.251083Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:47:11.377293Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:47:11.377561Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:47:11.430721Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:47:11.432336Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:47:11.432391Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:47:11.432421Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:47:41.883821Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:47:42.494802Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:47:42.620352Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:47:42.620667Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:47:42.694098Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:47:42.696040Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:47:42.696090Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:47:42.696121Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:48:13.496593Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:48:14.154795Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:48:14.277794Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:48:14.278024Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:48:14.348999Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:48:14.350682Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:48:14.350729Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:48:14.350759Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:48:44.830819Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:48:45.529495Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:48:45.664751Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:48:45.665140Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:48:45.767999Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:48:45.769434Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:48:45.769484Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:48:45.769519Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:49:16.618716Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:49:17.238301Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:49:17.363526Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:49:17.363832Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:49:17.446526Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:49:17.448032Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:49:17.448077Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:49:17.448456Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:49:47.903867Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:49:48.510166Z","level":"error","event":"Warning: Ignoring non-Spark config property: None","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:49:48.639583Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:49:48.639892Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:49:48.702150Z","level":"error","event":"Failed to import: /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":415,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o0.set.\n: java.lang.NullPointerException: null key\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:88)\n\tat org.apache.spark.SparkConf.set(SparkConf.scala:83)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py","lineno":405,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":883,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":241,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":14,"name":"<module>"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py","lineno":497,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":515,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":203,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py","lineno":248,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/pyspark/conf.py","lineno":143,"name":"set"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-27T23:49:48.703549Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:49:48.703593Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:49:48.703623Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:49:55.853981Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:49:56.600565Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:49:56.600851Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:49:56.724293Z","level":"error","event":"26/01/27 23:49:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:49:57.268102Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:49:57.268180Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:49:57.268212Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:50:28.219410Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:50:29.024760Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:50:29.025530Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:50:29.086814Z","level":"error","event":"26/01/27 23:50:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:50:29.526753Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:50:29.526844Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:50:29.526877Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:51:00.376398Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:51:01.224852Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:51:01.225830Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:51:01.336300Z","level":"error","event":"26/01/27 23:51:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:51:01.783457Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:51:01.783539Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:51:01.783572Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:51:32.732593Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:51:33.477881Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:51:33.478534Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:51:33.576733Z","level":"error","event":"26/01/27 23:51:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:51:34.007883Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:51:34.008154Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:51:34.008211Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:52:04.949009Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:52:05.683065Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:52:05.683553Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:52:05.791871Z","level":"error","event":"26/01/27 23:52:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:52:06.212782Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:52:06.212861Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:52:06.212893Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:52:37.163087Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:52:37.914003Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:52:37.914493Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:52:38.026123Z","level":"error","event":"26/01/27 23:52:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:52:38.458173Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:52:38.458437Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:52:38.458497Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:53:08.959760Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:53:09.755006Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:53:09.755540Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:53:09.922544Z","level":"error","event":"26/01/27 23:53:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:53:10.361961Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:53:10.362200Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:53:10.362256Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:53:41.306977Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:53:42.033399Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:53:42.033828Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:53:42.154511Z","level":"error","event":"26/01/27 23:53:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:53:42.574398Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:53:42.574628Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:53:42.574684Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:54:13.471140Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:54:14.174605Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:54:14.175065Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:54:14.302449Z","level":"error","event":"26/01/27 23:54:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:54:14.720975Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:54:14.721060Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:54:14.721092Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:54:45.590469Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:54:46.315366Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:54:46.315598Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:54:46.436799Z","level":"error","event":"26/01/27 23:54:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:54:46.870458Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:54:46.870539Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:54:46.870569Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:55:17.749248Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:55:18.461241Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:55:18.461751Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:55:18.599456Z","level":"error","event":"26/01/27 23:55:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:55:19.014065Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:55:19.014142Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:55:19.014176Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:55:49.939237Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:55:50.683778Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:55:50.684226Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:55:50.794785Z","level":"error","event":"26/01/27 23:55:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:55:51.223635Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:55:51.223939Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:55:51.224002Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:56:21.708834Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:56:22.531020Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:56:22.531632Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:56:22.626804Z","level":"error","event":"26/01/27 23:56:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:56:23.096156Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:56:23.096380Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:56:23.096436Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:56:48.450298Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:56:49.176785Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:56:49.177585Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:56:49.303050Z","level":"error","event":"26/01/27 23:56:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:56:49.751841Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:56:49.751934Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:56:49.751968Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:57:20.245483Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:57:20.986000Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:57:20.986716Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:57:21.113814Z","level":"error","event":"26/01/27 23:57:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:57:21.553791Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:57:21.553872Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:57:21.553903Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:57:41.378575Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:57:42.124156Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:57:42.124698Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:57:42.220416Z","level":"error","event":"26/01/27 23:57:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:57:42.643775Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:57:42.643861Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:57:42.643892Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:58:13.120165Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:58:13.891796Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:58:13.893749Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:58:14.004420Z","level":"error","event":"26/01/27 23:58:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:58:14.477825Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:58:14.477926Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:58:14.477963Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:58:45.300967Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:58:46.119670Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:58:46.120204Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:58:46.196388Z","level":"error","event":"26/01/27 23:58:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:58:46.606981Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:58:46.607071Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:58:46.607103Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:59:17.459297Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:59:18.291682Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:59:18.292160Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:59:18.360282Z","level":"error","event":"26/01/27 23:59:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:59:18.858758Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:59:18.858847Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:59:18.858879Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:59:49.723856Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:59:50.481095Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:59:50.481611Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:59:50.576156Z","level":"error","event":"26/01/27 23:59:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:59:51.012999Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:59:51.013107Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:59:51.013142Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}

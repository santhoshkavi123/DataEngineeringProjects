{"timestamp":"2026-01-27T23:50:04.454583Z","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-01-27T23:50:04.455039Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:50:05.182874Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:50:05.183135Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:50:05.267118Z","level":"error","event":"26/01/27 23:50:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:50:05.737169Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:50:05.737268Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:50:05.737312Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:50:05.753651Z","level":"info","event":"Done. Returned value was: ","logger":"airflow.task.operators.airflow.providers.standard.operators.python.BranchPythonOperator","filename":"python.py","lineno":216}
{"timestamp":"2026-01-27T23:50:05.753722Z","level":"info","event":"Branch into ","logger":"airflow.task.operators.airflow.providers.standard.operators.python.BranchPythonOperator","filename":"branch.py","lineno":44}
{"timestamp":"2026-01-27T23:50:05.753902Z","level":"info","event":"Following branch {''}","logger":"airflow.task.operators.airflow.providers.standard.operators.python.BranchPythonOperator","filename":"skipmixin.py","lineno":146}
{"timestamp":"2026-01-27T23:50:05.753975Z","level":"error","event":"Task failed with exception","logger":"task","filename":"task_runner.py","lineno":1056,"error_detail":[{"exc_type":"AirflowException","exc_value":"'branch_task_ids' must contain only valid task_ids. Invalid tasks found: {''}.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1004,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1405,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/sdk/bases/operator.py","lineno":417,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/standard/operators/branch.py","lineno":108,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/standard/operators/branch.py","lineno":50,"name":"do_branch"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/standard/utils/skipmixin.py","lineno":157,"name":"skip_all_except"}],"is_group":false,"exceptions":[]}]}

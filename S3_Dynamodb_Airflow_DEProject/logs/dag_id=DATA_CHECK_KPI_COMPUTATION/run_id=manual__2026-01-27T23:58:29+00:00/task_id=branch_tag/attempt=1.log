{"timestamp":"2026-01-27T23:58:38.118110Z","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-01-27T23:58:38.118449Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_pyspark_glue.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-27T23:58:38.800199Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:58:38.800456Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:58:38.903712Z","level":"error","event":"26/01/27 23:58:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2026-01-27T23:58:39.350671Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:58:39.350759Z","level":"warning","event":"The `airflow.operators.python.BranchPythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.BranchPythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:58:39.350792Z","level":"warning","event":"The `airflow.operators.empty.EmptyOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.empty.EmptyOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/dag_pyspark_glue.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2026-01-27T23:58:39.364559Z","level":"info","event":"Done. Returned value was: success_task","logger":"airflow.task.operators.airflow.providers.standard.operators.python.BranchPythonOperator","filename":"python.py","lineno":216}
{"timestamp":"2026-01-27T23:58:39.364630Z","level":"info","event":"Branch into success_task","logger":"airflow.task.operators.airflow.providers.standard.operators.python.BranchPythonOperator","filename":"branch.py","lineno":44}
{"timestamp":"2026-01-27T23:58:39.364778Z","level":"info","event":"Following branch {'success_task'}","logger":"airflow.task.operators.airflow.providers.standard.operators.python.BranchPythonOperator","filename":"skipmixin.py","lineno":146}
{"timestamp":"2026-01-27T23:58:39.364829Z","level":"error","event":"Task failed with exception","logger":"task","filename":"task_runner.py","lineno":1056,"error_detail":[{"exc_type":"AirflowException","exc_value":"'branch_task_ids' must contain only valid task_ids. Invalid tasks found: {'success_task'}.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1004,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1405,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/sdk/bases/operator.py","lineno":417,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/standard/operators/branch.py","lineno":108,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/standard/operators/branch.py","lineno":50,"name":"do_branch"},{"filename":"/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/standard/utils/skipmixin.py","lineno":157,"name":"skip_all_except"}],"is_group":false,"exceptions":[]}]}
